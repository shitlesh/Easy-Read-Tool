{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b5e9b546c21026",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Required Essential Libraries ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ec259",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]==4.31.0\n",
    "!pip install huggingface-hub\n",
    "!pip install nltk\n",
    "!pip install rouge-score\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c2cfbe833a4a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset Preparation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1733b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import tqdm as notebook_tqdm\n",
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "raw_xsum_dataset = load_dataset(\"EdinburghNLP/xsum\", split = 'train', trust_remote_code= 'True')\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee7dca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_xsum_dataset = raw_xsum_dataset.select(range(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecb2f3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['document', 'summary', 'id'],\n",
      "    num_rows: 50000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(sub_xsum_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b196379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': 'The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we\\'re neglected or forgotten,\" she said.\\n\"That may not be true but it is perhaps my perspective over the last few days.\\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\\nThe Labour Party\\'s deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.', 'summary': 'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.', 'id': '35232142'}\n"
     ]
    }
   ],
   "source": [
    "print(sub_xsum_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58ef0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_xsum_dataset=sub_xsum_dataset.train_test_split(train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dd0034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': \"The 22-year-old has joined on a one-year deal with the option of a second, and is Barrow's sixth summer signing.\\nHe started his career at Fulham before moving to QPR where he failed to make a first-team appearance.\\nFitzpatrick moved to Wimbledon in 2014 but only played 13 games, and had a loan spell in the National League with Torquay last term, scoring three goals.\\nFind all the latest football transfers on our dedicated page.\", 'summary': 'National League club Barrow have signed winger David Fitzpatrick following his release by AFC Wimbledon.', 'id': '40432537'}\n"
     ]
    }
   ],
   "source": [
    "print(split_xsum_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0af6346d14c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Preprocessing #\n",
    "## Text Splitter ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b9c8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e20dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    inputs = [doc if doc is not None else \"\" for doc in examples['document']]\n",
    "    summaries = [summ if summ is not None else \"\" for summ in examples['summary']]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(summaries, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1feaa95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81aaffbb10134543af332d4411704e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b26b987c5d4c22857d1446ca19e2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = split_xsum_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943fa00b",
   "metadata": {},
   "source": [
    "## Model Definition ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe0d540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8058b129",
   "metadata": {},
   "source": [
    "### Data Collator ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6c8a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=\"google-t5/t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4d4af",
   "metadata": {},
   "source": [
    "### Evaluate Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f799f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (0.24.5)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/text_summary/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Using cached evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45c5cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d09d2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1845b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "class ExtendedMetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"epoch\": [],\n",
    "            \"eval_rouge1\": [],\n",
    "            \"eval_rouge2\": [],\n",
    "            \"eval_rougeL\": [],\n",
    "        }\n",
    "        \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            epoch = logs.get(\"epoch\")\n",
    "            eval_rouge1 = logs.get(\"eval_rouge1\")\n",
    "            eval_rouge2 = logs.get(\"eval_rouge2\")\n",
    "            eval_rougeL = logs.get(\"eval_rougeL\")\n",
    "            \n",
    "\n",
    "            if epoch is not None:\n",
    "                self.metrics[\"epoch\"].append(epoch)\n",
    "            if eval_rouge1 is not None:\n",
    "                self.metrics[\"eval_rouge1\"].append(eval_rouge1)\n",
    "            if eval_rouge2 is not None:\n",
    "                self.metrics[\"eval_rouge2\"].append(eval_rouge2)\n",
    "            if eval_rougeL is not None:\n",
    "                self.metrics[\"eval_rougeL\"].append(eval_rougeL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aa3da8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon (MPS) device for training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"Using Apple Silicon (MPS) device for training.\")\n",
    "else:\n",
    "    print(\"MPS device not available. Falling back to CPU.\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fc6c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d41befc9d79473da1b37fe778686f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 37\u001b[0m\n\u001b[1;32m     24\u001b[0m extended_metrics_callback \u001b[38;5;241m=\u001b[39m ExtendedMetricsCallback()\n\u001b[1;32m     26\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     27\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     28\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[extended_metrics_callback]\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/trainer.py:2289\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2289\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2292\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2295\u001b[0m ):\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/trainer.py:3328\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3328\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3334\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/trainer.py:3373\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3372\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3373\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3374\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3375\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1702\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1702\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1712\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1713\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1714\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1715\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1716\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1106\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1092\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1093\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         output_attentions,\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:686\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    684\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    696\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:593\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    584\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    591\u001b[0m ):\n\u001b[1;32m    592\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 593\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    603\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text_summary/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:523\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    518\u001b[0m value_states \u001b[38;5;241m=\u001b[39m project(\n\u001b[1;32m    519\u001b[0m     hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv, key_value_states, past_key_value[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# compute scores\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_relative_attention_bias:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, TrainingArguments, Trainer\n",
    "import torch \n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(f\"Using MPS device: {device}\")\n",
    "else:\n",
    "    print(\"MPS device not available. Falling back to CPU.\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    fp16 = True,\n",
    "    use_cpu = False\n",
    ")\n",
    "\n",
    "extended_metrics_callback = ExtendedMetricsCallback()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[extended_metrics_callback]\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3976fcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: You will be responsible for managing the way your Direct Payments are spent, if you employ a Personal Assistant.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Define paths\n",
    "model_path = './best_saved_model_10'  \n",
    "tokenizer_path = './best_saved_token_10'  \n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# Example prompt (input text) for summarization\n",
    "input_text = \"You will be responsible for managing the way that your Direct Payments are spent. This means that if you employ a Personal Assistant directly, you will be classed as their employer.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate the summary (adjust max_length and num_beams as needed)\n",
    "summary_ids = model.generate(input_ids, max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "# Decode the generated summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated summary\n",
    "print(\"Generated Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cf67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract metrics from callback\n",
    "epochs = extended_metrics_callback.metrics[\"epoch\"]\n",
    "eval_rouge1 = extended_metrics_callback.metrics[\"eval_rouge1\"]\n",
    "eval_rouge2 = extended_metrics_callback.metrics[\"eval_rouge2\"]\n",
    "eval_rougeL = extended_metrics_callback.metrics[\"eval_rougeL\"]\n",
    "\n",
    "print(f'Epochs: {epochs}'/n)\n",
    "print(f'Rouge - 1 Score: {eval_rouge1}'/n)\n",
    "print(f'Rouge - 2 Score: {eval_rouge2}'/n)\n",
    "print(f'Rouge - L Score: {eval_rougeL}'/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9fbc6",
   "metadata": {},
   "source": [
    "# Model Summary #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95996f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "import os\n",
    "\n",
    "def load_custom_model(model_path):\n",
    "    # Load the model using AutoModel from transformers\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "def summarize_custom_model(model_path, output_file):\n",
    "    # Load your model using the function defined above\n",
    "    model = load_custom_model(model_path)\n",
    "    \n",
    "    # Open the file in write mode and keep it open for all writing operations\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Get basic information\n",
    "        model_type = f\"Model type: {type(model).__name__}\\n\"\n",
    "        f.write(model_type)\n",
    "    \n",
    "        # Load and print the config\n",
    "        config = AutoConfig.from_pretrained(model_path)\n",
    "        config_str = f\"Model configuration:\\n{config}\\n\"\n",
    "        f.write(config_str)\n",
    "    \n",
    "        # Print model parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        total_param_str = f\"Total parameters: {total_params}\\n\"\n",
    "        f.write(total_param_str)\n",
    "\n",
    "# Use the function\n",
    "summarize_custom_model('best_saved_model_10', 'summary_gen_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a965cab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary saved as summary_gen_model.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModel, AutoConfig\n",
    "import os\n",
    "import io\n",
    "\n",
    "def create_model_summary_image(model_path, output_file='summary_gen_model.png'):\n",
    "    # Load the model and config\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    config = AutoConfig.from_pretrained(model_path)\n",
    "    \n",
    "    # Gather model details\n",
    "    model_type = type(model).__name__\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    config_dict = config.to_dict()\n",
    "    files_in_directory = os.listdir(model_path)\n",
    "\n",
    "    # Create the figure and axis\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    fig.suptitle(f\"Model Summary: T5ForConditionalGeneration\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Model info text\n",
    "    info_text = f\"Total Parameters: {total_params:,}\"\n",
    "\n",
    "    ax1.text(0.05, 0.95, info_text, verticalalignment='top', fontsize=10, \n",
    "             family='monospace', transform=ax1.transAxes)\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Bar chart of parameter counts per layer\n",
    "    layer_params = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        layer = name.split('.')[0]\n",
    "        layer_params[layer] = layer_params.get(layer, 0) + param.numel()\n",
    "\n",
    "    layers = list(layer_params.keys())\n",
    "    counts = list(layer_params.values())\n",
    "\n",
    "    ax2.bar(layers, counts)\n",
    "    ax2.set_title(\"Parameter Count per Layer\", fontweight='bold')\n",
    "    ax2.set_xlabel(\"Layers\", fontweight='bold')\n",
    "    ax2.set_ylabel(\"Parameter Count\", fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Model summary saved as {output_file}\")\n",
    "\n",
    "# Use the function\n",
    "create_model_summary_image('best_saved_model_10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
